<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>hunt3ri.github.io</title><link href="https://hunt3ri.github.io/" rel="alternate"></link><link href="https://hunt3ri.github.io/feeds/all.atom.xml" rel="self"></link><id>https://hunt3ri.github.io/</id><updated>2019-11-20T22:20:00+00:00</updated><entry><title>Faustian Pacts and Software Excellence</title><link href="https://hunt3ri.github.io/faustian-pacts-and-software-excellence.html" rel="alternate"></link><published>2019-11-20T22:20:00+00:00</published><updated>2019-11-20T22:20:00+00:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2019-11-20:/faustian-pacts-and-software-excellence.html</id><summary type="html">&lt;p&gt;I saw this tweet recently and it sparked a few thoughts as it neatly gets to the heart of the biggest challenge in software – getting to done.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I saw this tweet recently and it sparked a few thoughts as it neatly gets to the heart of the biggest challenge in software – getting to done.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;P1: Aren&amp;#39;t you ashamed of writing code like this?&lt;br&gt;P2: What do you mean by &amp;quot;this&amp;quot;?&lt;br&gt;P1: Sky-high cyclomatic complexity, inconsistent naming, &amp;amp; duplication.&lt;br&gt;P2: Oh, I thought you meant &amp;quot;profitable&amp;quot;, and the answer is no I&amp;#39;m not ashamed.&lt;/p&gt;&amp;mdash; Kent Beck (@KentBeck) &lt;a href="https://twitter.com/KentBeck/status/1190052930843336704?ref_src=twsrc%5Etfw"&gt;October 31, 2019&lt;/a&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;In my experience there is very often a tension on any sizable software project between the desire of the business to get the software in front of customers as quickly as possible and the engineering team’s desire to ensure the code and architecture is of a high enough quality to make refactoring, scaling, testing and addition of new features as easy as possible.  Both desires are equally valid.&lt;/p&gt;
&lt;p&gt;The business needs to expand market share, ship code, have happy customers and get paid.  Possibly by being first to market.  Possibly because commitments and contracts have been signed promising a hard delivery date.&lt;/p&gt;
&lt;p&gt;Equally developers understand the value of flexible architecture, code that is easy to refactor, test and debug.  Further developers know that without these things code becomes harder to work with, meaning quality is hard to ensure, which leads to bugs and delays in delivery and ultimately unhappy customers.&lt;/p&gt;
&lt;p&gt;The tension comes from the assumption on both sides that the other should see their view as perfectly obvious and correct.  Both tribes are worrying about the same thing from a different view point.  Simplistically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The business worries that if the customer doesn’t get their software, we won’t get paid and we’ll be out of a job&lt;/li&gt;
&lt;li&gt;The dev team worries that if the software isn’t right we’ll be shipping slow buggy software, we won’t get paid and we’ll be out of a job.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is in the middle of these two tribes and this argument that the senior/lead developer will find themselves.  And it is here that both sides have to communicate and trust each other.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Faust" src="https://hunt3ri.github.io/images/faust-1.jpg#centre"&gt;&lt;/p&gt;
&lt;h2&gt;Communication&lt;/h2&gt;
&lt;p&gt;At the start of the project we could agree (simplistically):&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We must ship this project by June 2020, otherwise we lose the contract to our competitor.  We need to make some pragmatic decisions, take on a certain amount of technical debt.  Once we deliver we won’t promise any major new features until the technical debt is resolved.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Trust&lt;/h2&gt;
&lt;p&gt;Regarding trust.  The business needs to trust the team that they will deliver and make the necessary pragmatic decisions.  The developers need to trust that the business will allow them the necessary space to address the technical debt.&lt;/p&gt;
&lt;h2&gt;Profit&lt;/h2&gt;
&lt;p&gt;Which takes us back to the tweet.  Code that is profitable but with an amount of tech debt is acceptable as long as each side understands the reasons and the trust exists to resolve as/if needed.&lt;/p&gt;
&lt;h2&gt;Faust&lt;/h2&gt;
&lt;p&gt;Unfortunately in many software projects the above turns into a Faustian pact for the dev team.  Reluctantly they allow the technical debt to build up trusting that time will be given to resolve it.  In the meantime the business signs more deals, or demands new features with harder deadlines and the project becomes exactly what the dev team feared - unwieldy, slow and buggy, and stress increases.&lt;/p&gt;
&lt;p&gt;Excellent teams and businesses understand this, and ensure that both deadlines are hit and code quality is high, with time allowed to address technical debt.   In the end it’s only the excellent teams that will succeed.&lt;/p&gt;</content><category term="Software Development"></category></entry><entry><title>Address Search OS OpenNames with PostGIS, SQLAlchemy and Python – PART 2</title><link href="https://hunt3ri.github.io/address-search-os-opennames-with-postgis-sqlalchemy-and-python-part-2.html" rel="alternate"></link><published>2017-06-27T22:20:00+01:00</published><updated>2017-06-27T22:20:00+01:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2017-06-27:/address-search-os-opennames-with-postgis-sqlalchemy-and-python-part-2.html</id><summary type="html">&lt;p&gt;In Part 2 we look at writing a simple Python 3 CLI app that will show you how easy it is to integrate this powerful functionality into your apps and APIs.  Other than Python the only dependency we need is the SQLAlchemy ORM to let our app communicate with Postgres&lt;/p&gt;</summary><content type="html">&lt;p&gt;Part 1 of this post outlined how to configure a PostGIS database to allow us to run Full Text searches against the OS OpenNames dataset.&lt;/p&gt;
&lt;p&gt;In Part 2 we look at writing a simple Python 3 CLI app that will show you how easy it is to integrate this powerful functionality into your apps and APIs.  Other than Python the only dependency we need is the &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy ORM&lt;/a&gt; to let our app communicate with Postgres.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Address Search" src="https://hunt3ri.github.io/images/address-search.jpg#centre"&gt;&lt;/p&gt;
&lt;h2&gt;Installing SQLAlchemy&lt;/h2&gt;
&lt;p&gt;SQLAlchemy can be installed using pip.  It is dependent on psycopg2, which you may struggle to install on Mac without Postgres present, which is frustrating (however solutions can be found on Stack Overflow)&lt;/p&gt;
&lt;h2&gt;A simple address search CLI&lt;/h2&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;create_engine&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.ext.declarative&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;declarative_base&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.dialects.postgresql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TSVECTOR&lt;/span&gt;
  &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sqlalchemy.orm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sessionmaker&lt;/span&gt;

  &lt;span class="c1"&gt;# Create DB Session&lt;/span&gt;
  &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_engine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;postgresql://iain:password@localhost:5432/Real-World&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;Session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sessionmaker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

  &lt;span class="n"&gt;Base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;declarative_base&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

  &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;OpenNames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;__tablename__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;open_names&amp;#39;&lt;/span&gt;

      &lt;span class="c1"&gt;# Map DB columns we&amp;#39;re interested in &lt;/span&gt;
      &lt;span class="n"&gt;ogc_fid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;primary_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TSVECTOR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

      &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;search_address&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;search_for&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
          &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_for&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

          &lt;span class="n"&gt;or_search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search_for&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; | &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Append OR operator to every word searched&lt;/span&gt;
          &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OpenNames&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OpenNames&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;textsearchable&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;or_search&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;postgresql_reconfig&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

          &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;address&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Address you want to search for&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

      &lt;span class="n"&gt;open_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OpenNames&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="n"&gt;open_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search_address&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;address&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;Let me draw your attention to…&lt;/h2&gt;
&lt;p&gt;Hopefully this script is fairly easy to follow, but there are a couple of lines to draw your attention to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Line 4&lt;/strong&gt; – Note we have to tell SQLAlchemy we’re using the Postgres dialect so it understands TSVECTOR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lines 8&lt;/strong&gt; – 12 is simply SQLAlchemy boiler plate that sets up our connection and session for the app.  You’ll need to swap out the connection details for your own&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lines 17-20&lt;/strong&gt; I’ve chosen to map only 3 columns, you’ll probably want to map more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Line 25&lt;/strong&gt; – is very important, here we append the OR operator to every word the user has supplied, meaning we’re returning addresses.  You could extend this to allow the user to specify on exact match operator and change this to an &amp;amp; search.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Line 26&lt;/strong&gt; – Finally note we ask SQLAlchemy to match our search, and importantly we must supply the &lt;strong&gt;postgresql_reconfig&lt;/strong&gt; param to say we’re searching in English.  This is vital or you wont get the matches you expect.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Running our app&lt;/h2&gt;
&lt;p&gt;We can run our app from the command line simply by entering the following command&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;address_search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;forth street&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Ends&lt;/h2&gt;
&lt;p&gt;Hopefully you can see how easy it would be take the above code and integrate it into your apps and APIs.  I hope you’ve found these tutorials useful.  Happy text searching.&lt;/p&gt;</content><category term="Programming"></category></entry><entry><title>Address Search OS OpenNames with PostGIS, SQLAlchemy and Python – PART 1</title><link href="https://hunt3ri.github.io/address-search-os-opennames-with-postgis-sqlalchemy-and-python-part-1.html" rel="alternate"></link><published>2017-06-20T10:20:00+01:00</published><updated>2017-06-20T10:20:00+01:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2017-06-20:/address-search-os-opennames-with-postgis-sqlalchemy-and-python-part-1.html</id><summary type="html">&lt;p&gt;In this two part post we’ll look at implementing an address search using the Ordnance Survey Open Names dataset.  We’ll use the power of Postgres with the PostGIS extension leveraging it’s built in Full Text Search, and use Python and the SQLAlchemy ORM to create a simple CLI.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this two part post we’ll look at implementing an address search using the &lt;a href="https://www.ordnancesurvey.co.uk/business-government/products/open-map-names"&gt;Ordnance Survey Open Names&lt;/a&gt; dataset.  We’ll use the power of Postgres with the PostGIS extension leveraging it’s built in &lt;a href="https://www.postgresql.org/docs/current/textsearch.html"&gt;Full Text Search&lt;/a&gt;, and use Python and the &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt; ORM to create a simple CLI.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Address Search" src="https://hunt3ri.github.io/images/address-search.jpg#centre"&gt;&lt;/p&gt;
&lt;h2&gt;Part 1 – Data Load and DB Config Address Data&lt;/h2&gt;
&lt;p&gt;The UK is very badly served for free address data.  The best we have is the Ordnance Survey OpenNames dataset.  It will work as a Postcode lookup or a street finder (at a push), but the dataset would require a lot of additional processing to be a useful address search.  OS really want you to purchase &lt;a href="https://www.ordnancesurvey.co.uk/business-government/products/addressbase"&gt;AddressBase&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That said, OpenNames will suffice for this example and it should be easy to extend the example to a fuller dataset if you’re lucky enough to have one.&lt;/p&gt;
&lt;h2&gt;Loading Data to PostGIS&lt;/h2&gt;
&lt;p&gt;You can download OpenNames as either CSV, or GML.  I’d recommend GML as it’s simpler to load it into PostGIS using &lt;a href="https://gdal.org/programs/ogr2ogr.html"&gt;OGR2OGR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once you unzip the archive you’ll see that the files are referenced according to the British National Grid, so you can load as much or as little as you want.&lt;/p&gt;
&lt;p&gt;We’ll load NS68 which contains addresses in my home town of Stirling, as follows (swap out the values for your db):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ogr2ogr -f PostgreSQL PG:&lt;span class="s2"&gt;&amp;quot;host=localhost dbname=Real-World port=5432 user=iain password=password&amp;quot;&lt;/span&gt; NS68.gml -progress -nln open_names --config PG_USE_COPY YES
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You should now have a new table called open_names containing the addressing info.&lt;/p&gt;
&lt;p&gt;Note if you want to load more gml files just use the &lt;strong&gt;-append&lt;/strong&gt; flag:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ogr2ogr -f PostgreSQL PG:&lt;span class="s2"&gt;&amp;quot;host=localhost dbname=Real-World port=5432 user=iain password=password&amp;quot;&lt;/span&gt; NS88.gml -append -progress -nln open_names --config PG_USE_COPY YES
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Setting up Full Text Search&lt;/h2&gt;
&lt;p&gt;We now have our open_names table, but no text search column.  So we can add a textsearchable column which must be of type &lt;a href="https://www.postgresql.org/docs/current/datatype-textsearch.html"&gt;TSVECTOR&lt;/a&gt; as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;ALTER&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;open_names&lt;/span&gt; &lt;span class="k"&gt;ADD&lt;/span&gt; &lt;span class="k"&gt;COLUMN&lt;/span&gt; &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="nb"&gt;TSVECTOR&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can populate the column by using the built in function &lt;a href="https://www.postgresql.org/docs/current/textsearch-controls.html"&gt;TO_TSVECTOR&lt;/a&gt;, this tokenises the words based on the supplied config, in our case english.  However, &lt;a href="https://www.postgresql.org/docs/current/textsearch-configuration.html"&gt;multiple configs are supported&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;UPDATE&lt;/span&gt; &lt;span class="n"&gt;open_names&lt;/span&gt; &lt;span class="k"&gt;SET&lt;/span&gt; &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TO_TSVECTOR&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;text&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;localid&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you look at the data in your new column you’ll see that it now contains text tokens representing the address data.&lt;/p&gt;
&lt;h2&gt;Increase accuracy by concatenating multiple columns&lt;/h2&gt;
&lt;p&gt;Note that we’re concatenating 2 columns together in this update statement – &lt;strong&gt;text&lt;/strong&gt; and &lt;strong&gt;localid&lt;/strong&gt;.  In our case the reason for doing this is that the postcode in the &lt;strong&gt;localid&lt;/strong&gt; column is stored without a space, meaning our search will return a result if the user enters a postcode without a space.&lt;/p&gt;
&lt;p&gt;However, it should be clear if we had better address data, we could concat multiple columns.  Meaning if a user searched for “1 Main St, Stirling, FK3 4GG” we would be able to return an accurate match.&lt;/p&gt;
&lt;h2&gt;Add an Index for faster searching&lt;/h2&gt;
&lt;p&gt;Now that we have data set up we can add an index to our new column which will ensure searches are fast:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;INDEX&lt;/span&gt; &lt;span class="n"&gt;textsearch_idx&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;open_names&lt;/span&gt; &lt;span class="k"&gt;USING&lt;/span&gt; &lt;span class="n"&gt;GIN&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;textsearchable&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Let’s do some searches&lt;/h2&gt;
&lt;p&gt;Now lets query our new column to see if we can find some matches using the &lt;a href="https://www.postgresql.org/docs/current/textsearch-controls.html"&gt;TO_TSQUERY&lt;/a&gt; function&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="k"&gt;FROM&lt;/span&gt;   &lt;span class="n"&gt;open_names&lt;/span&gt; 
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="o"&gt;@@&lt;/span&gt; &lt;span class="n"&gt;TO_TSQUERY&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;avenue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we find we have 41 streets in Stirling area containing the word avenue.  You’ll note that I don’t need to worry about lowercase, uppercase or where the word might appear in the string.  Full text search takes care of that for me 🙂&lt;/p&gt;
&lt;p&gt;The @@ operator basically means that the query matches the tsvector column.&lt;/p&gt;
&lt;h2&gt;Using AND and OR for better matches&lt;/h2&gt;
&lt;p&gt;A very powerful feature of Postgres’ Full Text Search is the ability to find matches contain all or some of the words in the query using the AND &amp;amp; operator or the OR | operator, as these examples show:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;open_names&lt;/span&gt;
&lt;span class="k"&gt;where&lt;/span&gt; &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="o"&gt;@@&lt;/span&gt; &lt;span class="n"&gt;to_tsquery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;forth &amp;amp; view&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we only return one result Forth View which contains both Forth and View, if we change this to an OR search:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;open_names&lt;/span&gt;
&lt;span class="k"&gt;where&lt;/span&gt; &lt;span class="n"&gt;textsearchable&lt;/span&gt; &lt;span class="o"&gt;@@&lt;/span&gt; &lt;span class="n"&gt;to_tsquery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;forth | view&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We get 7 results including Forth View, Bruce View, Forth Place.&lt;/p&gt;
&lt;p&gt;Again it should be easy to see how powerful text searches could be built for complex text documents.&lt;/p&gt;
&lt;h2&gt;A final note on Triggers&lt;/h2&gt;
&lt;p&gt;While our address data is fairly static, if you had a table where users were regularly editing address data, or any other columns you wanted to run a full text search on, you should consider adding a trigger to keep the TSVECTOR column up to date, &lt;a href="https://www.postgresql.org/docs/9.5/textsearch-features.html#TEXTSEARCH-UPDATE-TRIGGERS"&gt;as outlined here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Up Next&lt;/h2&gt;
&lt;p&gt;Hopefully Part 1 has demonstrated how it is very easy to set up powerful text searching in Postgres.  In Part 2 we’ll look at how we can use Python and SQLAlchemy to allow you to integrate this functionality into your apps and APIs.&lt;/p&gt;
&lt;p&gt;So for our example the trigger would look like:&lt;/p&gt;</content><category term="Programming"></category></entry><entry><title>Restoring a Postgres database to AWS RDS using Docker</title><link href="https://hunt3ri.github.io/restoring-a-postgres-database-to-aws-rds-using-docker.html" rel="alternate"></link><published>2017-05-23T21:22:00+01:00</published><updated>2017-05-23T21:22:00+01:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2017-05-23:/restoring-a-postgres-database-to-aws-rds-using-docker.html</id><summary type="html">&lt;p&gt;In this post I look at using Docker to restore a Postgres dump file to a Postgres database running in the cloud on AWS RDS.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post I look at using Docker to restore a Postgres dump file to a Postgres database running in the cloud on &lt;a href="https://aws.amazon.com/rds/"&gt;AWS RDS&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Keep it clean&lt;/h2&gt;
&lt;p&gt;One of the big selling points of docker, for me, is that I can have lots of apps and utils running in nice containers on my dev laptop, without having to install them locally.  This ensures my laptop stays nice and responsive and I don’t clutter/break my laptop with lots of weird dependencies and running processes that I’m then too scared to delete.&lt;/p&gt;
&lt;p&gt;Postgres is a good example – I don’t want to install it locally, but I do need access to the command line tools like &lt;a href="https://www.postgresql.org/docs/current/app-psql.html"&gt;psql&lt;/a&gt; and &lt;a href="https://www.postgresql.org/docs/current/app-pgrestore.html"&gt;pg_restore&lt;/a&gt;, to be able to work with my databases effectively.&lt;/p&gt;
&lt;p&gt;One way of accessing these tools would be to ssh onto the AWS cloud instances, but there’s a bunch of reasons most pertinently security (not to mention the faff) why you’d want to avoid that every time you want to run some sql.  So let’s look at how we use Docker to ease the pain instead.&lt;/p&gt;
&lt;h2&gt;Start Me Up&lt;/h2&gt;
&lt;p&gt;With Docker installed you can build this simple Dockerfile to create a local Postgres container.  The User and Password env vars aren’t strictly required, however, if you want to actually connect to the containerised DB, it’s pretty handy&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="s"&gt;postgres&lt;/span&gt;

&lt;span class="k"&gt;ENV&lt;/span&gt; POSTGRES_USER postgres
&lt;span class="k"&gt;ENV&lt;/span&gt; POSTGRES_PASSWORD password
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;ou can build, run and connect to the container as follows (assumes you are on Mac)&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;  &lt;span class="n"&gt;mkdir&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;
  &lt;span class="n"&gt;vi&lt;/span&gt; &lt;span class="n"&gt;Dockerfile&lt;/span&gt;   &lt;span class="c1"&gt;# Copy Docker commands listed above into your local Dockerfile&lt;/span&gt;
  &lt;span class="n"&gt;docker&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;postgres&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;
  &lt;span class="n"&gt;docker&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Users&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;iainhunter&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;postgres&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;loader&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="mi"&gt;5432&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5432&lt;/span&gt; &lt;span class="n"&gt;postgres&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;
  &lt;span class="n"&gt;docker&lt;/span&gt; &lt;span class="n"&gt;ps&lt;/span&gt;
  &lt;span class="n"&gt;docker&lt;/span&gt; &lt;span class="n"&gt;exec&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;imageId&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;bash&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Note line 4 where I map the data-load dir I created at line 1 to a new directory called data-loader inside my container.  This means that when I copy the Postgres dump file into my local data-load directory, it will be available to the postgres tools available in the container.&lt;/p&gt;
&lt;p&gt;Line 6  allows me to connect to the container, swap the imageId  for your locally running containerID.&lt;/p&gt;
&lt;h2&gt;Restoring your database with pg_restore&lt;/h2&gt;
&lt;p&gt;I’ll assume you already have a Postgres database set up within the AWS cloud.  So now we have connected to our container, we can use pg_restore to use restore our dumpfile into AWS (note this command will prompt you for the admin password)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pg_restore —host&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;youHost&amp;gt;.eu-west-1.rds.amazonaws.com –port&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5432&lt;/span&gt; –username&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;yourAdminUser&amp;gt; –password –dbname&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;yourDB&amp;gt;  /data-loader/dumpfile.dmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;A note on schemas&lt;/h2&gt;
&lt;p&gt;If you’re doing a partial restore, you may want to restore your dumpfile to a separate schema.  Unfortunately there appears to be no way to do this from the command line.  What you have to do is to rename the public schema, create a new public schema and restore into that, then reverse the process.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/4191653/i-want-to-restore-the-database-with-a-different-schema/16311908#16311908"&gt;This StackOverflow answer outlines the process.&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Restore Complete&lt;/h2&gt;
&lt;p&gt;You should now have a complete restore of your dumpfile in the cloud.  Please add comments if anything is unclear.&lt;/p&gt;</content><category term="Software Development"></category></entry><entry><title>Running Mongo 3.2 in Docker on OSX</title><link href="https://hunt3ri.github.io/running-mongo-32-in-docker-on-osx.html" rel="alternate"></link><published>2016-01-12T21:22:00+00:00</published><updated>2016-01-12T21:22:00+00:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2016-01-12:/running-mongo-32-in-docker-on-osx.html</id><summary type="html">&lt;p&gt;Quick post after smashing my head off the desk for 5 hours trying to understand why I couldn’t get Mongo 3.2 running in a Docker container on my Mac.  Hopefully this post spares others the elastoplasts 🙂&lt;/p&gt;</summary><content type="html">&lt;p&gt;Quick post after smashing my head off the desk for 5 hours trying to understand why I couldn’t get Mongo 3.2 running in a Docker container on my Mac.  Hopefully this post spares others the elastoplasts 🙂&lt;/p&gt;
&lt;p&gt;&lt;img alt="Address Search" src="https://hunt3ri.github.io/images/mongo.png#centre"&gt;&lt;/p&gt;
&lt;h2&gt;Pitfall #1 – Mongo cannot write data to the host OSX machine&lt;/h2&gt;
&lt;p&gt;There are three factors that cause this issue:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A lot of mongo/docker docs tell you to mount a local volume&lt;/li&gt;
&lt;li&gt;By default &lt;a href="https://docs.docker.com/machine/"&gt;docker-machine&lt;/a&gt; uses the virtualbox driver to create a local VM&lt;/li&gt;
&lt;li&gt;Mongo uses &lt;a href="https://en.wikipedia.org/wiki/Mmap"&gt;mmap&lt;/a&gt; to turbo-charge access to files on disk&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These facts led me (by way of this &lt;a href="https://github.com/Parallels/docker-machine-parallels/issues/28"&gt;issue&lt;/a&gt;) to the fact that there’s been an &lt;a href="https://www.virtualbox.org/ticket/819"&gt;ancient known issue&lt;/a&gt; on VirtualBox that basically says docker ain’t going to be able to read/write files with mmap.&lt;/p&gt;
&lt;p&gt;So it’s pointless trying to tell mongo, via docker, to mount a local data volume, as the above bug means mongo isn’t going to be able to access it.  (careful reading of the &lt;a href="https://hub.docker.com/_/mongo/"&gt;Docker Hub mongo docs&lt;/a&gt; may allow you to divine this, but it’s not at all obvious)&lt;/p&gt;
&lt;h2&gt;Solution – Create a data volume in the container rather than the host.&lt;/h2&gt;
&lt;p&gt;Like always once you understand the problem, the solution is simple.  We can tell docker to create a data volume in the container rather than the host, as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker run –name my-local-mongo -v mongo-data:/data/db -p &lt;span class="m"&gt;27017&lt;/span&gt;:27017 -d mongo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In my (still) early days with docker I’d come across these cli commands which contained absolutely no description of WTF all the switches are doing, so a quick breakdown:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;–name my-local-mongo&lt;/strong&gt; – This tells docker to give the container the name “my-local-mongo” rather than generating a name like tuftybeaver&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-v mongo-data:/data/db&lt;/strong&gt; – This is the key switch, here we tell docker to create a new data volume called mongo-data and mount it as /data/db which is the default location mongo wants to write data to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-p 27017:27017&lt;/strong&gt; – Here we tell docker to bind the container port 27017 to port 27017 on the host vm, allowing us to access docker locally.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-d&lt;/strong&gt; – This switch tells docker to run the process detached so we’re not running interactively.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all has gone well docker should be running your mongo container successfully.  A quick &lt;strong&gt;docker ps&lt;/strong&gt; will show your running container.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;docker logs -f my-local-mongo&lt;/strong&gt; – will allow you to follow the log files&lt;/p&gt;
&lt;h2&gt;Pitfall #2 – I can’t connect to mongo from localhost&lt;/h2&gt;
&lt;p&gt;This is the classic docker school boy error, that everyone makes.  The first time you do this you’ll be patting yourself on the back as you type localhost:27017 into your connection string and then wonder why the hell docker isn’t found.&lt;/p&gt;
&lt;p&gt;This is because everything is actually running on your local docker virtual machine.  To find the IP of the VM enter &lt;strong&gt;docker-machine ls&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You should see the URL listed something like this tcp://192.168.99.100:2376 You need to snarf this IP for your connection string.  The easiest way to sanity check that’s it all working is bash it into your browser, eg for this example:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://192.168.99.100:27017"&gt;http://192.168.99.100:27017/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The mongo database should helpfully respond with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;It looks like you are trying to access MongoDB over HTTP on the native driver port.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Demonstrating that your mongo db is running and responding to idiots trying to speak to it over HTTP 🙂&lt;/p&gt;
&lt;h2&gt;Pitfall #3 – No collections are displayed in RoboMongo&lt;/h2&gt;
&lt;p&gt;This was a real head scratcher, I was pretty sure everything was working, and yet &lt;a href="https://robomongo.org/"&gt;RoboMongo&lt;/a&gt; wasn’t showing a damn thing.  This was a classic case of me Sherlock Holmes style spending 2 hours &lt;em&gt;eliminating the impossible, to find whatever remains, however improbable, must be the truth&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So in a turn up for the books, there was no bug in my code!!  It &lt;a href="https://stackoverflow.com/questions/34462083/cannot-see-collections-in-robomongo-on-windows-10/34462109"&gt;turns out&lt;/a&gt; by default Mongo 3.2 uses the WiredTiger storage engine, and RoboMongo can’t parse data stored in this format.&lt;/p&gt;
&lt;p&gt;So instead if you’re using Mongo 3.2 you should use MongoChef to connect to your db.  &lt;a href="https://studio3t.com/"&gt;MongoChef&lt;/a&gt; will show you all your lovely collections, living within your containerised Mongo.&lt;/p&gt;
&lt;p&gt;Hope the above helps, thanks 🙂&lt;/p&gt;</content><category term="Software Development"></category></entry><entry><title>Achieving Consensus – It’s so funny, how we don’t talk anymore</title><link href="https://hunt3ri.github.io/achieving-consensus-its-so-funny-how-we-dont-talk-anymore.html" rel="alternate"></link><published>2015-12-16T10:20:00+00:00</published><updated>2015-12-16T10:20:00+00:00</updated><author><name>Iain Hunter</name></author><id>tag:hunt3ri.github.io,2015-12-16:/achieving-consensus-its-so-funny-how-we-dont-talk-anymore.html</id><summary type="html">&lt;p&gt;Walk into any office and there can usually be found a surplus of opinion and a dearth of consensus and agreement. While the crowd may be wise, as individuals we all know we’re right and damn any fool who disagrees with us.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Walk into any office and there can usually be found a surplus of opinion and a dearth of consensus and agreement. While the crowd may be wise, as individuals we all know we’re right and damn any fool who disagrees with us.&lt;/p&gt;
&lt;p&gt;A quick perusal of the comments section of any, even moderately controversial post, and you’ll see an echo chamber of hundreds of people carefully explaining why each other’s opinion is completely and hopelessly wrong.&lt;/p&gt;
&lt;p&gt;The rarest phrase on the internet, is – “That’s a compelling argument, you’ve completely changed my mind”&lt;/p&gt;
&lt;p&gt;&lt;img alt="Address Search" src="https://hunt3ri.github.io/images/wrong.png#centre"&gt;&lt;/p&gt;
&lt;p&gt;In fact, the comments sections of most blogs are now so poisonous that the creators of the content, and the majority of its readers, don’t even bother to “Read below the line”.  Worse, people with interesting and unusual opinions are intimidated into not broadcasting them in the first place.&lt;/p&gt;
&lt;p&gt;I’d like to say we can all agree that this is a terrible state of affairs, but as I’ve explained, that’s merely an invitation to be pointed at 100 other blog posts explaining why I’m wrong.&lt;/p&gt;
&lt;p&gt;So all we can say is that opinions are cheap, and getting consensus is the hard part.  For a contemporary example – the recent Paris climate change talks are both simultaneously The &lt;a href="https://www.theguardian.com/environment/2015/dec/13/paris-climate-deal-cop-diplomacy-developing-united-nations"&gt;World’s Greatest Diplomatic Achievement&lt;/a&gt;, and &lt;a href="https://www.theguardian.com/environment/georgemonbiot/2015/dec/12/paris-climate-deal-governments-fossil-fuels"&gt;A Squalid Retrenchment&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Picking battles and getting permission&lt;/h2&gt;
&lt;p&gt;I wanted to write this post, not because I have the answer to generating constructive discussion on the internet (I wish).  But because I think teams and individuals (including myself) struggle on the projects we work on every day – not for want of ability but for want of consensus and clarity on what we want to achieve.&lt;/p&gt;
&lt;p&gt;Because we all instinctively understand the difficulty and energy required to get a group of people to agree on just about anything – the path of least resistance is to avoid the discussion in the first place. Indeed by having the discussion you expose yourself to the risk that your argument will not carry the day, and you’ll be forced down a road you’d prefer not to be on. So it’s easy to understand why tough decisions and “honest” conversations are avoided and “difficult” people worked around.&lt;/p&gt;
&lt;p&gt;The old cliché “Pick your battles” or my personal favourite “Better to ask forgiveness than get permission” are undoubted truisms, but they come with a cost.  By avoiding the battles and not getting the permission, in other words not getting consensus, you can find yourself isolated when you hit the inevitable bumps in the road.  As you’ve neatly provided those excluded from the decision with a convenient scape-goat.  eg – “Well if he’d asked me, of course I’d have told him that was a terrible idea.”&lt;/p&gt;
&lt;p&gt;Or as Sun-Tzu put it more pithily:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_“Victorious warriors win first and then go to war, while defeated warriors go to war first and then seek to win”&lt;/strong&gt;_ &lt;/p&gt;
&lt;h2&gt;Are you thinking what I’m thinking?&lt;/h2&gt;
&lt;p&gt;I’m certainly not advocating that every decision needs to be ran past the team, but decisions that will impact more than one or two people or that will have a significant impact on what is delivered,  and when it will be delivered, should be discussed as a group.&lt;/p&gt;
&lt;p&gt;Keeping the team and the business involved in the decision making process will cost you time and you’ll inevitably have to slaughter some of your personal sacred cows, to reach an approach everyone can agree on.  However, the prize is worth the pain.&lt;/p&gt;
&lt;p&gt;That prize is a clearly articulated plan that both the team and business believes in and much more importantly – &lt;strong&gt;are invested in&lt;/strong&gt;.  Reason being – because you’ve arrived at the plan as a group, the group should want it to succeed as they all have some some skin in the game.&lt;/p&gt;
&lt;p&gt;The drive and pressure to “Get stuff done” and the small windows many agile methodologies allow for meetings and planning between sprints means it’s easy to skip getting the team bought into the plan and approach. This is a mistake.&lt;/p&gt;
&lt;p&gt;Rather than thinking of getting consensus as an exercise in cost/pain/stress think of it as an extremely valuable deliverable and vital part of leading a team (unfortunately the cost/pain/stress are still there 😉&lt;/p&gt;
&lt;p&gt;In the end it’s just all about talking, and remember to heed Cliff’s warning…&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/GzjX18psf9A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;</content><category term="Software Development"></category></entry></feed>